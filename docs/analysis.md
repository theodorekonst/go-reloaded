# Analysis

## 1ï¸âƒ£ Problem Description

go-reloaded is a text transformation tool written in Go that processes files with special transformation tags and outputs corrected text. It reads an input file, identifies transformation commands like `(hex)`, `(up, 2)`, or `(cap)`, applies the corresponding changes, and writes the result to an output file.

The goal is to build a robust, maintainable system that handles multiple transformation types while preserving text structure and following clean architecture principles.

## 2ï¸âƒ£ Transformation Rules

### Number Conversions

**`(hex)`** â†’ Converts the previous word from hexadecimal to decimal
```
42 (hex) â†’ 66
```

**`(bin)`** â†’ Converts the previous word from binary to decimal
```
10 (bin) â†’ 2
```

### Case Transformations

**`(up)`** â†’ Makes the previous word UPPERCASE
```
word (up) â†’ WORD
```

**`(low)`** â†’ Makes the previous word lowercase
```
WORD (low) â†’ word
```

**`(cap)`** â†’ Makes the previous word Title Case
```
word (cap) â†’ Word
```

**`(up|low|cap, n)`** â†’ Applies transformation to n previous words (counting only words)
```
these words (up, 2) â†’ THESE WORDS
```

### Text Corrections

**Article correction** â†’ Changes a to an before vowels or h
```
a apple â†’ an apple, a honest â†’ an honest
```

**Punctuation spacing** â†’ Attaches punctuation to previous word, one space after
```
word ,space â†’ word, space
```

**Punctuation groups** â†’ Treats ..., !?, ?! as single units
```
word ... space â†’ word... space
```

**Quote tightening** â†’ Removes spaces inside quotes
```
' spaced words ' â†’ 'spaced words'
```

## 3ï¸âƒ£ Edge Cases & Error Handling

- **Invalid numbers:** `ZZ (hex)` or `102 (bin)` â†’ keep word, remove tag
- **Missing previous word:** `(cap) hello` â†’ remove tag, keep text
- **Invalid syntax:** `(up, 0)` or malformed tags â†’ safely ignored
- **Word counting:** In `(up, n)`, count only words, skip punctuation/spaces
- **Article with punctuation:** `a, honest` â†’ `an, honest` (works across punctuation)
- **Preserve structure:** Maintain original line breaks and formatting

## 4ï¸âƒ£ Architecture Decision: Pipeline vs FSM

### What are the approaches?

**Pipeline (Assembly Line)**
- Each stage does one specific job and passes result to next stage
- Like a factory: Tokenize â†’ Convert â†’ Transform â†’ Format â†’ Output

**FSM (State Machine)**
- Single processor that changes behavior based on current state
- Like a smart robot: Reading â†’ Found Tag â†’ Apply Rule â†’ Continue

### Pipeline Implementation

```
Input Text
    â†“
[ Tokenize ] â† Split into Word, Space, Punct, Tag tokens
    â†“
[ Hex Conversion ] â† Handle (hex) tags
    â†“
[ Bin Conversion ] â† Handle (bin) tags  
    â†“
[ Case Transforms ] â† Handle (up), (low), (cap) tags
    â†“
[ Quote Tightening ] â† Remove spaces in quotes
    â†“
[ Article Correction ] â† Fix aâ†’an
    â†“
[ Space Normalization ] â† Collapse multiple spaces
    â†“
[ Punctuation Spacing ] â† Fix punctuation attachment
    â†“
Output Text
```

### Why Pipeline Order Matters

1. **Numbers first** â†’ Independent of other transforms
2. **Case after numbers** â†’ Might need to transform converted numbers
3. **Quotes before articles** â†’ Article rules might be affected by quote changes
4. **Articles before spacing** â†’ Grammar fixes before formatting
5. **Space normalization before punctuation** â†’ Clean up spaces first
6. **Punctuation last** â†’ Final formatting pass

### Architecture Comparison

| Criterion | Pipeline | FSM |
|-----------|----------|-----|
| Readability | âœ… Clean & modular | âŒ Complex single function |
| Testing | âœ… Unit test each stage | âŒ Must test entire flow |
| Debugging | âœ… Easy to isolate issues | âŒ Hard to find problems |
| Maintenance | âœ… Modify one stage | âŒ Change affects whole system |
| Team Development | âœ… Parallel work on stages | âŒ Single point of conflict |
| Performance | âŒ Multiple passes | âœ… Single pass |
| Memory Usage | âŒ Intermediate results | âœ… Process as you go |

### ğŸ¯ Decision: Pipeline Architecture

Chosen Pipeline because:

- **Code Quality:** More readable and maintainable
- **Testing:** Each transform independently testable
- **Team Friendly:** Multiple developers can work on different stages
- **Debugging:** Easy to trace issues through pipeline
- **Extensibility:** New rules are just new pipeline stages
- **Learning:** Better for junior developers to understand

## 5ï¸âƒ£ Implementation Strategy

### Token-Based Processing

```go
type Token struct {
    K    TokenType  // Word, Space, Punct, Tag, Group, Quote
    Text string     // Actual content
}
```

**Benefits:**
- Preserves original spacing and structure
- Enables precise transformations without losing context
- Maintains exact formatting including line breaks

### Transform Functions

Each transform follows the same pattern:

```go
func ApplyTransform(tokens []Token) []Token {
    // 1. Find relevant tokens
    // 2. Apply transformation
    // 3. Remove processed tags
    // 4. Return modified token stream
}
```

### Error Handling Philosophy

- **Graceful degradation:** Invalid input â†’ keep original, drop tag
- **Preserve structure:** Never corrupt original text format
- **Fail safe:** Unknown tags pass through to other transforms

## 6ï¸âƒ£ Testing Strategy

### Golden Tests

- **Descriptive names:** `case_transforms.txt`, `number_conversion.txt`, `article_correction.txt`
- **Input/Output pairs:** Each `.txt` has corresponding `.want.txt`
- **Comprehensive coverage:** All transformation rules tested
- **Integration testing:** Full pipeline validation

### Test Categories

- **case_transforms** â†’ Tests all case operations and ranges
- **number_conversion** â†’ Tests hex/bin conversions and error cases
- **article_correction** â†’ Tests aâ†’an grammar rules

## 7ï¸âƒ£ Project Structure

```
go-reloaded/
â”œâ”€â”€ main.go                    # CLI interface
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ io/file.go            # File operations & overwrite handling
â”‚   â”œâ”€â”€ token/token.go        # Tokenization & reconstruction
â”‚   â”œâ”€â”€ transform/            # One file per transformation rule
â”‚   â”‚   â”œâ”€â”€ convert.go        # Hex/binary conversions
â”‚   â”‚   â”œâ”€â”€ case.go           # Case transformations
â”‚   â”‚   â”œâ”€â”€ article.go        # Article corrections
â”‚   â”‚   â”œâ”€â”€ quotes.go         # Quote tightening
â”‚   â”‚   â”œâ”€â”€ punct.go          # Punctuation spacing
â”‚   â”‚   â””â”€â”€ space.go          # Space normalization
â”‚   â””â”€â”€ pipeline/pipeline.go  # Transform orchestration
â”œâ”€â”€ testdata/                 # Golden test files
â””â”€â”€ internal_test/            # Test runner
```

### Design Principles

- **Single Responsibility:** Each file has one clear purpose
- **Separation of Concerns:** CLI, processing, and I/O are separate
- **No External Dependencies:** Pure Go standard library
- **Junior Developer Friendly:** Simple, readable code structure

## 8ï¸âƒ£ Success Criteria

### Functional Requirements

- âœ… All transformation rules implemented correctly
- âœ… Edge cases handled gracefully
- âœ… Original text structure preserved
- âœ… Comprehensive error handling

### Quality Requirements

- âœ… Clean, maintainable architecture
- âœ… 100% test coverage of transformation rules
- âœ… Cross-platform compatibility
- âœ… Professional CLI interface

### Performance Requirements

- âœ… Linear time complexity O(n)
- âœ… Reasonable memory usage
- âœ… Fast execution for typical text files